import json
from openai import OpenAI
from tavily import TavilyClient
from django.conf import settings
from .utils import clean_context

openai = OpenAI(
    api_key=settings.GROQ_API_KEY, base_url="https://api.groq.com/openai/v1"
)
tavily = TavilyClient(api_key=settings.TAVILY_API_KEY)


def tavily_search(
    area, city, area_sqft, beds, baths, count, seed_index
):  # pylint: disable=R0913, R0917
    search_queries = [
        (
            f"recently sold properties in {area} {city} with price area_sqft "
            "beds baths 'sold date'"
        ),
        (
            f"site:homes.com {area} {city} 'recently sold' {area_sqft} sqft "
            f"{beds} beds {baths} baths price"
        ),
        (
            f"site:zillow.com {area} {city} 'recently sold' {area_sqft} sqft "
            f"{beds} beds {baths} baths with price"
        ),
        (
            f"site:redfin.com {area} {city} 'recently sold homes' {area_sqft} sqft "
            f"{beds} beds {baths} baths with price"
        ),
    ]

    # Tavily accurate search
    search_result = tavily.search(
        query=search_queries[seed_index],
        max_results=count,
        search_depth="advanced",
        include_raw_content=False,
        include_usage=True,
    )

    # Tavily Credit Usage
    tavily_credits = search_result.get("usage", {}).get("credits", "unknown")

    # Tavily Context
    context_text = "\n---\n".join(
        [
            f"Source: {res['url']}\nContent: {res['content']}"
            for res in search_result["results"]
        ]
    )

    context_text = clean_context(context_text)

    return context_text, tavily_credits


def groq_json_formatter(context_text, area, city):
    # Groq llama JSON extraction
    prompt = (
        f"You are a Real Estate Data Expert. Extract comparable properties for {area}, {city}.\n\n"
        f"RAW DATA:\n{context_text}\n\n"
        "STRICT RULES:\n"
        "1. Use ONLY the data provided above.\n"
        "2. Return ONLY a JSON object with a key 'properties' containing a list.\n"
        "3. Required Fields per object: [price, area_sqft, beds, baths].\n"
        "4. If ANY REQUIRED field is missing, 'None', or 'unknown', DO NOT EXTRACT THAT PROPERTY.\n"
        "5. Exclude any other fields."
    )

    response = openai.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0.0,  # Low temperature for strict extraction accuracy
        max_tokens=1000,
    )

    # Groq Credit Usage
    usage = response.usage

    # Extract the list from the JSON response
    data = json.loads(response.choices[0].message.content)
    return data.get("properties", []), usage


def groq_ai_insight_prompt(
    comps_sample, property_data, rating, breakdown, agent="GPT"
):  # pylint: disable=R0913, R0914, R0917
    """Groq gpt oss 120b"""

    title = property_data.get("title")
    price = property_data.get("price")
    sqft = property_data.get("area_sqft")
    beds = property_data.get("beds")
    baths = property_data.get("baths")

    math_context = json.dumps(breakdown, indent=2)

    system_role = (
        "You are a Senior Real Estate Investment Analyst. You are reviewing a property "
        "valuation generated by a regression algorithm. Your job is to translate raw "
        "scoring data into a polished executive summary for an investor.\n\n"
        "GUIDELINES:\n"
        "1. TRANSLATE DEBUG LOGS: If you see remarks like 'sqft discarded' or 'more price', "
        "understand this means the algorithm penalized the property for poor price-to-space "
        "efficiency. Translate this to: 'Premium pricing relative to square footage utility'.\n"
        "2. PRICE SENSITIVITY: If price_score is high, emphasize equity capture.\n"
        "3. TONE: Professional, objective, and data-driven. "
        "Do not use phrases like 'The algorithm says'.\n"
        "4. DO NOT use internal developer terms like 'bed_final', 'pps_score', or 'remarks'."
    )

    user_prompt = (
        f"PROPERTY UNDER REVIEW: {title}\n"
        f"Price: ${price:,} | {sqft} sqft | {beds} BR | {baths} BA\n\n"
        f"ALGORITHM DATA (Internal Metrics & Logic):\n{math_context}\n\n"
        f"COMPUTED RATING: {rating} / 5\n\n"
        f"MARKET DATA (Comps): {json.dumps(comps_sample[:10])}\n\n"
        "TASK: Provide a JSON object with this exact structure:\n"
        "{\n"
        "  'weighted_analysis': 'A single string where each line represents a score adjustment. "
        "Start each line with the raw score and a professional description. "
        "Example: +1.4 Exceptional Price-to-Value Gap\\n-0.5 Square Footage Utility Penalty',\n"
        "  'investment_summary': 'A professional 3-sentence "
        "executive summary explaining the rating.',\n"
        "  'pros': ['Detailed strength 1', 'Detailed strength 2'],\n"
        "  'cons': ['Detailed risk 1', 'Detailed risk 2']\n"
        "}"
    )

    if agent == "GPT":
        agent_model = "openai/gpt-oss-120b"
    else:
        agent_model = "qwen/qwen3-32b"

    response = openai.chat.completions.create(
        model=agent_model,
        messages=[
            {"role": "system", "content": system_role},
            {"role": "user", "content": user_prompt},
        ],
        response_format={"type": "json_object"},
        temperature=0.3,  # Lower temperature, more focus on math
    )

    # Groq Credit Usage
    usage = response.usage

    return json.loads(response.choices[0].message.content), usage
